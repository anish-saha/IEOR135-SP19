{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2019: Homework 06 \n",
    "\n",
    "## Name : \n",
    "\n",
    "Anish Saha\n",
    "\n",
    "## SID :\n",
    "\n",
    "26071616\n",
    "\n",
    "## Course (IEOR 135/290) :\n",
    "\n",
    "### Machine Learning\n",
    "\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction. We will cover these algorithms in class, but this is for you to have some hands on with these in scikit-learn. You can refer - https://github.com/ikhlaqsidhu/data-x/blob/master/05a-tools-predicition-titanic/titanic.ipynb\n",
    "\n",
    "Display all your outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    " # machine learning libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__ 1. Read __`diabetesdata.csv`__ file into a pandas dataframe. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  IsDiabetic\n",
       "0              6         148.0  72        0  33.6     0.627  50.0           1\n",
       "1              1           NaN  66        0  26.6     0.351  31.0           0\n",
       "2              8         183.0  64        0  23.3     0.672   NaN           1\n",
       "3              1           NaN  66       94  28.1     0.167  21.0           0\n",
       "4              0         137.0  40      168  43.1     2.288  33.0           1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read data & print the head\n",
    "df = pd.read_csv(\"diabetesdata.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Calculate the percentage of Null values in each column and display it. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TimesPregnant    0.000000\n",
       "glucoseLevel     0.044271\n",
       "BP               0.000000\n",
       "insulin          0.000000\n",
       "BMI              0.000000\n",
       "Pedigree         0.000000\n",
       "Age              0.042969\n",
       "IsDiabetic       0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum() / len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Split __`data`__  into  __`train_df`__ and __`test_df`__  with 15% as test.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 653, 115)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(999)\n",
    "\n",
    "idx = np.random.rand(len(df)) < 0.85\n",
    "train_df, test_df = df[idx], df[~idx]\n",
    "len(df), len(train_df), len(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Display the means of the features in train and test sets. Replace the null values in  __`train_df`__ and __`test_df`__  with the mean of EACH feature column separately for train and test. Display head of the dataframes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimesPregnant      3.983384\n",
      "glucoseLevel     120.787639\n",
      "BP                68.978852\n",
      "insulin           80.598187\n",
      "BMI               31.998943\n",
      "Pedigree           0.472144\n",
      "Age               33.606635\n",
      "IsDiabetic         0.345921\n",
      "dtype: float64\n",
      "TimesPregnant      2.981132\n",
      "glucoseLevel     122.417476\n",
      "BP                69.896226\n",
      "insulin           74.811321\n",
      "BMI               31.952830\n",
      "Pedigree           0.470208\n",
      "Age               31.784314\n",
      "IsDiabetic         0.367925\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/pandas/core/generic.py:5430: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train\n",
      "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree        Age  \\\n",
      "0              6    148.000000  72        0  33.6     0.627  50.000000   \n",
      "1              1    120.787639  66        0  26.6     0.351  31.000000   \n",
      "2              8    183.000000  64        0  23.3     0.672  33.606635   \n",
      "3              1    120.787639  66       94  28.1     0.167  21.000000   \n",
      "4              0    137.000000  40      168  43.1     2.288  33.000000   \n",
      "\n",
      "   IsDiabetic  \n",
      "0           1  \n",
      "1           0  \n",
      "2           1  \n",
      "3           0  \n",
      "4           1  \n",
      "\n",
      "Test\n",
      "    TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  IsDiabetic\n",
      "16              0    122.417476  84      230  45.8     0.551  31.0           1\n",
      "26              7    147.000000  76        0  39.4     0.257  43.0           1\n",
      "31              3    158.000000  76      245  31.6     0.851  28.0           1\n",
      "40              3    180.000000  64       70  34.0     0.271  26.0           0\n",
      "41              7    133.000000  84        0  40.2     0.696  37.0           0\n"
     ]
    }
   ],
   "source": [
    "print(train_df.mean())\n",
    "print(test_df.mean())\n",
    "\n",
    "train_df.fillna(train_df.mean(), inplace=True)\n",
    "test_df.fillna(test_df.mean(), inplace=True)\n",
    "\n",
    "print(\"\\nTrain\")\n",
    "print(train_df.head())\n",
    "print(\"\\nTest\")\n",
    "print(test_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Split __`train_df`__ & __`test_df`__   into  __`X_train`__, __`Y_train`__  and __`X_test`__, __`Y_test`__. __`Y_train`__  and __`Y_test`__ should only have the column we are trying to predict,  __`IsDiabetic`__.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train\n",
      "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree        Age\n",
      "0              6    148.000000  72        0  33.6     0.627  50.000000\n",
      "1              1    120.787639  66        0  26.6     0.351  31.000000\n",
      "2              8    183.000000  64        0  23.3     0.672  33.606635\n",
      "3              1    120.787639  66       94  28.1     0.167  21.000000\n",
      "4              0    137.000000  40      168  43.1     2.288  33.000000\n",
      "\n",
      "X_test\n",
      "    TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age\n",
      "16              0    122.417476  84      230  45.8     0.551  31.0\n",
      "26              7    147.000000  76        0  39.4     0.257  43.0\n",
      "31              3    158.000000  76      245  31.6     0.851  28.0\n",
      "40              3    180.000000  64       70  34.0     0.271  26.0\n",
      "41              7    133.000000  84        0  40.2     0.696  37.0\n",
      "\n",
      "y_train\n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: IsDiabetic, dtype: int64\n",
      "\n",
      "y_test\n",
      "16    1\n",
      "26    1\n",
      "31    1\n",
      "40    0\n",
      "41    0\n",
      "Name: IsDiabetic, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = train_df.drop(\"IsDiabetic\", axis=1), test_df.drop(\"IsDiabetic\", axis=1)\n",
    "y_train, y_test = train_df[\"IsDiabetic\"], test_df[\"IsDiabetic\"]\n",
    "print(\"X_train\")\n",
    "print(X_train.head())\n",
    "print(\"\\nX_test\")\n",
    "print(X_test.head())\n",
    "print(\"\\ny_train\")\n",
    "print(y_train.head())\n",
    "print(\"\\ny_test\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Use this dataset to train perceptron, logistic regression and random forest models using 15% test split. Report training and test accuracies. Try different hyperparameter values for these models and see if you can improve your accuracies.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Model Performance:\n",
      "Training Accuracy: 0.7658610271903323\n",
      "Test Accuracy: 0.7830188679245284\n",
      "\n",
      "\n",
      "Optimized Logistic Regression Model Performance:\n",
      "Training Accuracy: 0.7719033232628398\n",
      "Test Accuracy: 0.7924528301886793\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 6a. Logistic Regression\n",
    "mod1 = LogisticRegression()\n",
    "mod1.fit(X_train, y_train)\n",
    "\n",
    "print(\"Logistic Regression Model Performance:\")\n",
    "y_pred_train = mod1.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod1.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "penalty = ['l1', 'l2']\n",
    "C = np.logspace(0, 5, 10)\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "clf = GridSearchCV(mod1, hyperparameters, cv=5, verbose=0)\n",
    "mod2 = clf.fit(X_train, y_train) # optimized hyperparameters\n",
    "\n",
    "print(\"Optimized Logistic Regression Model Performance:\")\n",
    "y_pred_train = mod2.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod2.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model Performance:\n",
      "Training Accuracy: 0.3776435045317221\n",
      "Test Accuracy: 0.39622641509433965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized Perceptron Model Performance:\n",
      "Training Accuracy: 0.6993957703927492\n",
      "Test Accuracy: 0.7169811320754716\n",
      "\n",
      "\n",
      "Multi-Layer Perceptron Model Performance:\n",
      "Training Accuracy: 0.6963746223564955\n",
      "Test Accuracy: 0.7075471698113207\n",
      "\n",
      "\n",
      "Optimized Multi-Layer Perceptron Model Performance:\n",
      "Training Accuracy: 0.7537764350453172\n",
      "Test Accuracy: 0.7452830188679245\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# 6b. Perceptron\n",
    "mod3 = Perceptron()\n",
    "mod3.fit(X_train, y_train)\n",
    "\n",
    "print(\"Perceptron Model Performance:\")\n",
    "y_pred_train = mod3.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod3.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))\n",
    "\n",
    "hyperparameters = { 'alpha': [0.0001, 0.05], 'fit_intercept': [True, False],\n",
    "                    'max_iter': [100, 1000], 'penalty': penalty }\n",
    "clf = GridSearchCV(mod3, hyperparameters, cv=5, verbose=0)\n",
    "mod4 = clf.fit(X_train, y_train) # optimized hyperparameters\n",
    "\n",
    "print(\"Optimized Perceptron Model Performance:\")\n",
    "y_pred_train = mod4.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod4.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))\n",
    "\n",
    "print(\"\\n\")      \n",
    "    \n",
    "# 6b. Multi-Layer Perceptron\n",
    "mod3 = MLPClassifier()\n",
    "mod3.fit(X_train, y_train)\n",
    "\n",
    "print(\"Multi-Layer Perceptron Model Performance:\")\n",
    "y_pred_train = mod3.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod3.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "hyperparameters = { 'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)], \n",
    "                    'alpha': [0.0001, 0.05], 'activation': ['tanh', 'relu'],\n",
    "                    'learning_rate': ['constant','adaptive'] }\n",
    "clf = GridSearchCV(mod3, hyperparameters, cv=5, verbose=0)\n",
    "mod4 = clf.fit(X_train, y_train) # optimized hyperparameters\n",
    "\n",
    "print(\"Optimized Multi-Layer Perceptron Model Performance:\")\n",
    "y_pred_train = mod4.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod4.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model Performance:\n",
      "Training Accuracy: 0.9833836858006042\n",
      "Test Accuracy: 0.7830188679245284\n",
      "\n",
      "\n",
      "Optimized Random Forest Model Performance:\n",
      "Training Accuracy: 0.918429003021148\n",
      "Test Accuracy: 0.8018867924528302\n"
     ]
    }
   ],
   "source": [
    "# 6c. Random Forest\n",
    "mod5 = RandomForestClassifier()\n",
    "mod5.fit(X_train, y_train)\n",
    "\n",
    "print(\"Random Forest Model Performance:\")\n",
    "y_pred_train = mod5.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod5.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 10)]\n",
    "max_depth.append(None)\n",
    "hyperparameters = { 'max_depth': max_depth, 'min_samples_split': [2, 5, 10],\n",
    "                    'max_features': ['auto', 'sqrt'], 'bootstrap': [True, False] }\n",
    "clf = GridSearchCV(mod5, hyperparameters, cv=5, verbose=0)\n",
    "mod6 = clf.fit(X_train, y_train) # optimized hyperparameters\n",
    "\n",
    "print(\"Optimized Random Forest Model Performance:\")\n",
    "y_pred_train = mod6.predict(X_train)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod6.predict(X_test)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7. For your logistic regression model - **\n",
    "\n",
    "**a . Compute the log probability of classes in  __`IsDiabetic`__ for the first 10 samples of your train set and display it. Also display the predicted class for those samples from your logistic regression model trained before. **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities for first 10 training samples\n",
      "[[-1.10942339 -0.40010307]\n",
      " [-0.17359275 -1.83658434]\n",
      " [-1.61647411 -0.22139221]\n",
      " [-0.1537507  -1.94831341]\n",
      " [-1.70591041 -0.20041259]\n",
      " [-0.18852481 -1.7613076 ]\n",
      " [-0.07912209 -2.57606337]\n",
      " [-0.99331984 -0.46258348]\n",
      " [-1.47067037 -0.26106793]\n",
      " [-0.05511131 -2.92582943]]\n",
      "\n",
      "\n",
      "Predicted Class for first 10 training samples\n",
      "[1 0 1 0 1 0 0 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Log Probabilities for first 10 training samples\")\n",
    "print(mod2.predict_log_proba(X_train)[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Predicted Class for first 10 training samples\")\n",
    "print(mod2.predict(X_train)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b . Now compute the log probability of classes in  __`IsDiabetic`__ for the first 10 samples of your test set and display it. Also display the predicted class for those samples from your logistic regression model trained before.\n",
    " (using the model trained on the training set)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Probabilities for first 10 training samples\n",
      "[[-0.47680148 -0.96960119]\n",
      " [-1.21847992 -0.35052146]\n",
      " [-0.88339004 -0.5333766 ]\n",
      " [-1.35006788 -0.30005519]\n",
      " [-1.03682156 -0.43785386]\n",
      " [-0.04436754 -3.137349  ]\n",
      " [-0.08413521 -2.51710276]\n",
      " [-0.20566261 -1.68258782]\n",
      " [-0.01692857 -4.08720499]\n",
      " [-0.02651673 -3.64320836]]\n",
      "\n",
      "\n",
      "Predicted Class for first 10 training samples\n",
      "[0 1 1 1 1 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Log Probabilities for first 10 training samples\")\n",
    "print(mod2.predict_log_proba(X_test)[:10])\n",
    "print(\"\\n\")\n",
    "print(\"Predicted Class for first 10 training samples\")\n",
    "print(mod2.predict(X_test)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c . What can you interpret from the log probabilities and the predicted classes?**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the outputs above, the first column represents the log probability that the sample is of class 0 [ `IsDiabetic` = 0 ], while the second column represents the log probability that the sample is of class 1 [ `IsDiabetic` = 1 ]. The  probability that a sample is of a certain class is computed using the formula: \n",
    "\n",
    "$$P(\\,\\text{sample}_j \\text{is not diabetic}) = e^{\\,a[j][0]} \\,\\,|\\,\\, P(\\,\\text{sample}_j \\text{is diabetic}) = e^{\\,a[j][1]} \\\\ \\text{for the }j^{th}\\text{ sample, and } a \\text{ is the array displayed above}$$\n",
    "\n",
    "The predicted class corresponds to the column with the higher log probability (and consequently, higher probability) value – or in other words, whichever log probability value is closer to 0 since all log probability values are negative. This can be confirmed by observing the outputs above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**8. Is mean imputation is the best type of imputation (as we did in 4.) to use? Why or why not? What are some other ways to impute the data?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean imputation is not the best type of imputation to use. This is because it often does not preserve relationships between variables (imputed values have zero correlation with other variables), presents biased metrics of standard error and variance, and can result in a biased sample mean. The only advantage is that it preserves the sample size. Some other ways to impute the data include hot-deck imputation, cold-deck imputation, regression imputation, and multiple imputation (ex: MICE, using chained equations, for when data is randomly missing)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit (2 pts) - MANDATORY for students enrolled in IEOR 290"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**9.  Implement the K-Nearest Neighbours (https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm) algorithm for k=1 from scratch in python (do not use KNN from existing libraries). KNN uses Euclidean distance to find nearest neighbors. Split your dataset into test and train as before. Also fill in the null values with mean of features as done earlier. Use this algorithm to predict values for 'IsDiabetic' for your test set. Display your accuracy. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MANUAL IMPLEMENTATION | K-Nearest Neighbors Model Performance:\n",
      "Training Accuracy: 1.0\n",
      "Test Accuracy: 0.7264150943396226\n"
     ]
    }
   ],
   "source": [
    "# K-Nearest Neighbors Classifier for k=1\n",
    "class KNN_Classifier():\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    def euclidean_dist(self, x1, x2):\n",
    "        distance = 0\n",
    "        for i in range(len(x1)):\n",
    "            distance = distance + (x1[i] - x2[i])**2\n",
    "        return distance\n",
    "    \n",
    "    def k_nearest(self, row, k=1):\n",
    "        best_dist = self.euclidean_dist(row, self.X_train[0])\n",
    "        best_idx = 0\n",
    "        for i in range(k, len(self.X_train)):\n",
    "            dist = self.euclidean_dist(row, self.X_train[i])\n",
    "            if dist < best_dist:\n",
    "                best_dist = dist\n",
    "                best_idx = i\n",
    "        return self.y_train[best_idx]\n",
    "\n",
    "    def predict(self, X_test, k=1):\n",
    "        result = []\n",
    "        for row in X_test:\n",
    "            label = self.k_nearest(row, k)\n",
    "            result.append(label)\n",
    "        return result\n",
    "\n",
    "mod7 = KNN_Classifier()\n",
    "mod7.fit(X_train.values, y_train.values)\n",
    "\n",
    "print(\"MANUAL IMPLEMENTATION | K-Nearest Neighbors Model Performance:\")\n",
    "y_pred_train = mod7.predict(X_train.values)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod7.predict(X_test.values)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SKLEARN IMPLEMENTATION | K-Nearest Neighbors Model Performance:\n",
      "Training Accuracy: 0.8096676737160121\n",
      "Test Accuracy: 0.7264150943396226\n"
     ]
    }
   ],
   "source": [
    "# Checking Implementation against SciKitLearn Library Implementation \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "mod8 = KNeighborsClassifier() \n",
    "mod8.fit(X_train, y_train)\n",
    "\n",
    "print(\"SKLEARN IMPLEMENTATION | K-Nearest Neighbors Model Performance:\")\n",
    "y_pred_train = mod8.predict(X_train.values)\n",
    "train_rmse = accuracy_score(y_train, y_pred_train)\n",
    "print(\"Training Accuracy: \" + str(train_rmse))\n",
    "y_pred_test = mod8.predict(X_test.values)\n",
    "test_rmse = accuracy_score(y_test, y_pred_test)\n",
    "print(\"Test Accuracy: \" + str(test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
